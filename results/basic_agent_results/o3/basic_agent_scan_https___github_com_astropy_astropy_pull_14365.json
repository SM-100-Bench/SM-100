{"repo_id": "astropy_astropy_14365", "bugs": [{"description": "FastBasic.__init__ uses a mutable default argument `default_kwargs={}`. This may cause unexpected shared state between instances because the same dictionary object is reused across calls if it gets mutated.", "file": "astropy/io/ascii/fastbasic.py", "line": 27}], "updated_files": {"/var/folders/hp/rv5nbb3140l0404lfjq_pq140000gn/T/tmps14_xr19/astropy/io/ascii/fastbasic.py": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\nimport copy\nimport re\nfrom collections import OrderedDict\n\nfrom astropy.table import Table\nfrom astropy.utils.misc import _set_locale\n\nfrom . import core, cparser\n\n\nclass FastBasic(metaclass=core.MetaBaseReader):\n    \"\"\"\n    This class is intended to handle the same format addressed by the\n    ordinary :class:`Basic` writer, but it acts as a wrapper for underlying C\n    code and is therefore much faster. Unlike the other ASCII readers and\n    writers, this class is not very extensible and is restricted\n    by optimization requirements.\n    \"\"\"\n\n    _format_name = \"fast_basic\"\n    _description = \"Basic table with custom delimiter using the fast C engine\"\n    _fast = True\n    fill_extra_cols = False\n    guessing = False\n    strict_names = False\n\n    def __init__(self, default_kwargs=None, **user_kwargs):\n        # Avoid mutable default argument\n        if default_kwargs is None:\n            default_kwargs = {}\n        # Make sure user does not set header_start to None for a reader\n        # that expects a non-None value (i.e. a number >= 0).  This mimics\n        # what happens in the Basic reader.\n        if (\n            default_kwargs.get(\"header_start\", 0) is not None\n            and user_kwargs.get(\"header_start\", 0) is None\n        ):\n            raise ValueError(\"header_start cannot be set to None for this Reader\")\n\n        # Set up kwargs and copy any user kwargs.  Use deepcopy user kwargs\n        # since they may contain a dict item which would end up as a ref to the\n        # original and get munged later (e.g. in cparser.pyx validation of\n        # fast_reader dict).\n        kwargs = copy.deepcopy(default_kwargs)\n        kwargs.update(copy.deepcopy(user_kwargs))\n\n        delimiter = kwargs.pop(\"delimiter\", \" \")\n        self.delimiter = str(delimiter) if delimiter is not None else None\n        self.write_comment = kwargs.get(\"comment\", \"# \")\n        self.comment = kwargs.pop(\"comment\", \"#\")\n        if self.comment is not None:\n            self.comment = str(self.comment)\n        self.quotechar = str(kwargs.pop(\"quotechar\", '\"'))\n        self.header_start = kwargs.pop(\"header_start\", 0)\n        # If data_start is not specified, start reading\n        # data right after the header line\n        data_start_default = user_kwargs.get(\n            \"data_start\", self.header_start + 1 if self.header_start is not None else 1\n        )\n        self.data_start = kwargs.pop(\"data_start\", data_start_default)\n        self.kwargs = kwargs\n        self.strip_whitespace_lines = True\n        self.strip_whitespace_fields = True\n\n    def _read_header(self):\n        # Use the tokenizer by default -- this method\n        # can be overridden for specialized headers\n        self.engine.read_header()\n\n    def read(self, table):\n        \"\"\"\n        Read input data (file-like object, filename, list of strings, or\n        single string) into a Table and return the result.\n        \"\"\"\n        if self.comment is not None and len(self.comment) != 1:\n            raise core.ParameterError(\"The C reader does not support a comment regex\")\n        elif self.data_start is None:\n            raise core.ParameterError(\n                \"The C reader does not allow data_start to be None\"\n            )\n        elif (\n            self.header_start is not None\n            and self.header_start < 0\n            and not isinstance(self, FastCommentedHeader)\n        ):\n            raise core.ParameterError(\n                \"The C reader does not allow header_start to be \"\n                \"negative except for commented-header files\"\n            )\n        elif self.data_start < 0:\n            raise core.ParameterError(\n                \"The C reader does not allow data_start to be negative\"\n            )\n        elif len(self.delimiter) != 1:\n            raise core.ParameterError(\"The C reader only supports 1-char delimiters\")\n        elif len(self.quotechar) != 1:\n            raise core.ParameterError(\n                \"The C reader only supports a length-1 quote character\"\n            )\n        elif \"converters\" in self.kwargs:\n            raise core.ParameterError(\n                \"The C reader does not support passing specialized converters\"\n            )\n        elif \"encoding\" in self.kwargs:\n            raise core.ParameterError(\n                \"The C reader does not use the encoding parameter\"\n            )\n        elif \"Outputter\" in self.kwargs:\n            raise core.ParameterError(\n                \"The C reader does not use the Outputter parameter\"\n            )\n        elif \"Inputter\" in self.kwargs:\n            raise core.ParameterError(\n                \"The C reader does not use the Inputter parameter\"\n            )\n        elif \"data_Splitter\" in self.kwargs or \"header_Splitter\" in self.kwargs:\n            raise core.ParameterError(\"The C reader does not use a Splitter class\")\n\n        self.strict_names = self.kwargs.pop(\"strict_names\", False)\n\n        # Process fast_reader kwarg, which may or may not exist (though ui.py will always\n        # pass this as a dict with at least 'enable' set).\n        fast_reader = self.kwargs.get(\"fast_reader\", True)\n        if not isinstance(fast_reader, dict):\n            fast_reader = {}\n\n        fast_reader.pop(\"enable\", None)\n        self.return_header_chars = fast_reader.pop(\"return_header_chars\", False)\n        # Put fast_reader dict back into kwargs.\n        self.kwargs[\"fast_reader\"] = fast_reader\n\n        self.engine = cparser.CParser(\n            table,\n            self.strip_whitespace_lines,\n            self.strip_whitespace_fields,\n            delimiter=self.delimiter,\n            header_start=self.header_start,\n            comment=self.comment,\n            quotechar=self.quotechar,\n            data_start=self.data_start,\n            fill_extra_cols=self.fill_extra_cols,\n            **self.kwargs,\n        )\n        conversion_info = self._read_header()\n        self.check_header()\n        if conversion_info is not None:\n            try_int, try_float, try_string = conversion_info\n        else:\n            try_int = {}\n            try_float = {}\n            try_string = {}\n\n        with _set_locale(\"C\"):\n            data, comments = self.engine.read(try_int, try_float, try_string)\n        out = self.make_table(data, comments)\n\n        if self.return_header_chars:\n            out.meta[\"__ascii_fast_reader_header_chars__\"] = self.engine.header_chars\n\n        return out\n\n    def make_table(self, data, comments):\n        \"\"\"Actually make the output table give the data and comments.\"\"\"\n        meta = OrderedDict()\n        if comments:\n            meta[\"comments\"] = comments\n\n        names = core._deduplicate_names(self.engine.get_names())\n        return Table(data, names=names, meta=meta)\n\n    def check_header(self):\n        names = self.engine.get_header_names() or self.engine.get_names()\n        if self.strict_names:\n            # Impose strict requirements on column names (normally used in guessing)\n            bads = [\" \", \",\", \"|\", \"\\t\", \"'\", '\"']\n            for name in names:\n                if (\n                    core._is_number(name)\n                    or len(name) == 0\n                    or name[0] in bads\n                    or name[-1] in bads\n                ):\n                    raise ValueError(\n                        f\"Column name {name!r} does not meet strict name requirements\"\n                    )\n        # When guessing require at least two columns\n        if self.guessing and len(names) <= 1:\n            raise ValueError(\n                f\"Table format guessing requires at least two columns, got {names}\"\n            )\n\n    def write(self, table, output):\n        \"\"\"\n        Use a fast Cython method to write table data to output,\n        where output is a filename or file-like object.\n        \"\"\"\n        self._write(table, output, {})\n\n    def _write(\n        self, table, output, default_kwargs, header_output=True, output_types=False\n    ):\n        # Fast writer supports only 1-d columns\n        core._check_multidim_table(table, max_ndim=1)\n\n        write_kwargs = {\n            \"delimiter\": self.delimiter,\n            \"quotechar\": self.quotechar,\n            \"strip_whitespace\": self.strip_whitespace_fields,\n            \"comment\": self.write_comment,\n        }\n        write_kwargs.update(default_kwargs)\n        # user kwargs take precedence over default kwargs\n        write_kwargs.update(self.kwargs)\n        writer = cparser.FastWriter(table, **write_kwargs)\n        writer.write(output, header_output, output_types)\n\n\nclass FastCsv(FastBasic):\n    \"\"\"\n    A faster version of the ordinary :class:`Csv` writer that uses the\n    optimized C parsing engine. Note that this reader will append empty\n    field values to the end of any row with not enough columns, while\n    :class:`FastBasic` simply raises an error.\n    \"\"\"\n\n    _format_name = \"fast_csv\"\n    _description = \"Comma-separated values table using the fast C engine\"\n    _fast = True\n    fill_extra_cols = True\n\n    def __init__(self, **kwargs):\n        super().__init__({\"delimiter\": \",\", \"comment\": None}, **kwargs)\n\n    def write(self, table, output):\n        \"\"\"\n        Override the default write method of `FastBasic` to\n        output masked values as empty fields.\n        \"\"\"\n        self._write(table, output, {\"fill_values\": [(core.masked, \"\")]})\n\n\nclass FastTab(FastBasic):\n    \"\"\"\n    A faster version of the ordinary :class:`Tab` reader that uses\n    the optimized C parsing engine.\n    \"\"\"\n\n    _format_name = \"fast_tab\"\n    _description = \"Tab-separated values table using the fast C engine\"\n    _fast = True\n\n    def __init__(self, **kwargs):\n        super().__init__({\"delimiter\": \"\\t\"}, **kwargs)\n        self.strip_whitespace_lines = False\n        self.strip_whitespace_fields = False\n\n\nclass FastNoHeader(FastBasic):\n    \"\"\"\n    This class uses the fast C engine to read tables with no header line. If\n    the names parameter is unspecified, the columns will be autonamed with\n    \"col{}\".\n    \"\"\"\n\n    _format_name = \"fast_no_header\"\n    _description = \"Basic table with no headers using the fast C engine\"\n    _fast = True\n\n    def __init__(self, **kwargs):\n        super().__init__({\"header_start\": None, \"data_start\": 0}, **kwargs)\n\n    def write(self, table, output):\n        \"\"\"\n        Override the default writing behavior in `FastBasic` so\n        that columns names are not included in output.\n        \"\"\"\n        self._write(table, output, {}, header_output=None)\n\n\nclass FastCommentedHeader(FastBasic):\n    \"\"\"\n    A faster version of the :class:`CommentedHeader` reader, which looks for\n    column names in a commented line. ``header_start`` denotes the index of\n    the header line among all commented lines and is 0 by default.\n    \"\"\"\n\n    _format_name = \"fast_commented_header\"\n    _description = \"Columns name in a commented line using the fast C engine\"\n    _fast = True\n\n    def __init__(self, **kwargs):\n        super().__init__({}, **kwargs)\n        # Mimic CommentedHeader's behavior in which data_start\n        # is relative to header_start if unspecified; see #2692\n        if \"data_start\" not in kwargs:\n            self.data_start = 0\n\n    def make_table(self, data, comments):\n        \"\"\"\n        Actually make the output table give the data and comments.  This is\n        slightly different from the base FastBasic method in the way comments\n        are handled.\n        \"\"\"\n        meta = OrderedDict()\n        if comments:\n            idx = self.header_start\n            if idx < 0:\n                idx = len(comments) + idx\n            meta[\"comments\"] = comments[:idx] + comments[idx + 1 :]\n            if not meta[\"comments\"]:\n                del meta[\"comments\"]\n\n        names = core._deduplicate_names(self.engine.get_names())\n        return Table(data, names=names, meta=meta)\n\n    def _read_header(self):\n        tmp = self.engine.source\n        commented_lines = []\n\n        for line in tmp.splitlines():\n            line = line.lstrip()\n            if line and line[0] == self.comment:  # line begins with a comment\n                commented_lines.append(line[1:])\n                if len(commented_lines) == self.header_start + 1:\n                    break\n\n        if len(commented_lines) <= self.header_start:\n            raise cparser.CParserError(\"not enough commented lines\")\n\n        self.engine.setup_tokenizer([commented_lines[self.header_start]])\n        self.engine.header_start = 0\n        self.engine.read_header()\n        self.engine.setup_tokenizer(tmp)\n\n    def write(self, table, output):\n        \"\"\"\n        Override the default writing behavior in `FastBasic` so\n        that column names are commented.\n        \"\"\"\n        self._write(table, output, {}, header_output=\"comment\")\n\n\nclass FastRdb(FastBasic):\n    \"\"\"\n    A faster version of the :class:`Rdb` reader. This format is similar to\n    tab-delimited, but it also contains a header line after the column\n    name line denoting the type of each column (N for numeric, S for string).\n    \"\"\"\n\n    _format_name = \"fast_rdb\"\n    _description = \"Tab-separated with a type definition header line\"\n    _fast = True\n\n    def __init__(self, **kwargs):\n        super().__init__({\"delimiter\": \"\\t\", \"data_start\": 2}, **kwargs)\n        self.strip_whitespace_lines = False\n        self.strip_whitespace_fields = False\n\n    def _read_header(self):\n        tmp = self.engine.source\n        line1 = \"\"\n        line2 = \"\"\n        for line in tmp.splitlines():\n            # valid non-comment line\n            if not line1 and line.strip() and line.lstrip()[0] != self.comment:\n                line1 = line\n            elif not line2 and line.strip() and line.lstrip()[0] != self.comment:\n                line2 = line\n                break\n        else:  # less than 2 lines in table\n            raise ValueError(\"RDB header requires 2 lines\")\n\n        # Tokenize the two header lines separately.\n        # Each call to self.engine.read_header by default\n        #  - calls _deduplicate_names to ensure unique header_names\n        #  - sets self.names from self.header_names if not provided as kwarg\n        #  - applies self.include_names/exclude_names to self.names.\n        # For parsing the types disable 1+3, but self.names needs to be set.\n        self.engine.setup_tokenizer([line2])\n        self.engine.header_start = 0\n        self.engine.read_header(deduplicate=False, filter_names=False)\n        types = self.engine.get_header_names()\n\n        # If no kwarg names have been passed, reset to have column names read from header line 1.\n        if types == self.engine.get_names():\n            self.engine.set_names([])\n        self.engine.setup_tokenizer([line1])\n        # Get full list of column names prior to applying include/exclude_names,\n        # which have to be applied to the unique name set after deduplicate.\n        self.engine.read_header(deduplicate=True, filter_names=False)\n        col_names = self.engine.get_names()\n        self.engine.read_header(deduplicate=False)\n        if len(col_names) != len(types):\n            raise core.InconsistentTableError(\n                \"RDB header mismatch between number of column names and column types\"\n            )\n        # If columns have been removed via include/exclude_names, extract matching types.\n        if len(self.engine.get_names()) != len(types):\n            types = [types[col_names.index(n)] for n in self.engine.get_names()]\n\n        if any(not re.match(r\"\\d*(N|S)$\", x, re.IGNORECASE) for x in types):\n            raise core.InconsistentTableError(\n                f\"RDB type definitions do not all match [num](N|S): {types}\"\n            )\n\n        try_int = {}\n        try_float = {}\n        try_string = {}\n\n        for name, col_type in zip(self.engine.get_names(), types):\n            if col_type[-1].lower() == \"s\":\n                try_int[name] = 0\n                try_float[name] = 0\n                try_string[name] = 1\n            else:\n                try_int[name] = 1\n                try_float[name] = 1\n                try_string[name] = 0\n\n        self.engine.setup_tokenizer(tmp)\n        return (try_int, try_float, try_string)\n\n    def write(self, table, output):\n        \"\"\"\n        Override the default writing behavior in `FastBasic` to\n        output a line with column types after the column name line.\n        \"\"\"\n        self._write(table, output, {}, output_types=True)\n", "/var/folders/hp/rv5nbb3140l0404lfjq_pq140000gn/T/tmps14_xr19/astropy/io/ascii/html.py": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\"\"\"An extensible HTML table reader and writer.\n\nhtml.py:\n  Classes to read and write HTML tables\n\n`BeautifulSoup <http://www.crummy.com/software/BeautifulSoup/>`_\nmust be installed to read HTML tables.\n\"\"\"\n\nimport warnings\nfrom copy import deepcopy\n\nfrom astropy.table import Column\nfrom astropy.utils.xml import writer\n\nfrom . import core\n\n\nclass SoupString(str):\n    \"\"\"\n    Allows for strings to hold BeautifulSoup data.\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        return str.__new__(cls, *args, **kwargs)\n\n    def __init__(self, val):\n        self.soup = val\n\n\nclass ListWriter:\n    \"\"\"\n    Allows for XMLWriter to write to a list instead of a file.\n    \"\"\"\n\n    def __init__(self, out):\n        self.out = out\n\n    def write(self, data):\n        self.out.append(data)\n\n\ndef identify_table(soup, htmldict, numtable):\n    \"\"\"\n    Checks whether the given BeautifulSoup tag is the table\n    the user intends to process.\n    \"\"\"\n    if soup is None or soup.name != \"table\":\n        return False  # Tag is not a <table>\n\n    elif \"table_id\" not in htmldict:\n        return numtable == 1\n    table_id = htmldict[\"table_id\"]\n\n    if isinstance(table_id, str):\n        return \"id\" in soup.attrs and soup[\"id\"] == table_id\n    elif isinstance(table_id, int):\n        return table_id == numtable\n\n    # Return False if an invalid parameter is given\n    return False\n\n\nclass HTMLInputter(core.BaseInputter):\n    \"\"\"\n    Input lines of HTML in a valid form.\n\n    This requires `BeautifulSoup\n    <http://www.crummy.com/software/BeautifulSoup/>`_ to be installed.\n    \"\"\"\n\n    def process_lines(self, lines):\n        \"\"\"\n        Convert the given input into a list of SoupString rows\n        for further processing.\n        \"\"\"\n        try:\n            from bs4 import BeautifulSoup\n        except ImportError:\n            raise core.OptionalTableImportError(\n                \"BeautifulSoup must be installed to read HTML tables\"\n            )\n\n        if \"parser\" not in self.html:\n            with warnings.catch_warnings():\n                # Ignore bs4 parser warning #4550.\n                warnings.filterwarnings(\n                    \"ignore\", \".*no parser was explicitly specified.*\"\n                )\n                soup = BeautifulSoup(\"\\n\".join(lines))\n        else:  # use a custom backend parser\n            soup = BeautifulSoup(\"\\n\".join(lines), self.html[\"parser\"])\n        tables = soup.find_all(\"table\")\n        for i, possible_table in enumerate(tables):\n            if identify_table(possible_table, self.html, i + 1):\n                table = possible_table  # Find the correct table\n                break\n        else:\n            if isinstance(self.html[\"table_id\"], int):\n                err_descr = f\"number {self.html['table_id']}\"\n            else:\n                err_descr = f\"id '{self.html['table_id']}'\"\n            raise core.InconsistentTableError(\n                f\"ERROR: HTML table {err_descr} not found\"\n            )\n\n        # Get all table rows\n        soup_list = [SoupString(x) for x in table.find_all(\"tr\")]\n\n        return soup_list\n\n\nclass HTMLSplitter(core.BaseSplitter):\n    \"\"\"\n    Split HTML table data.\n    \"\"\"\n\n    def __call__(self, lines):\n        \"\"\"\n        Return HTML data from lines as a generator.\n        \"\"\"\n        for line in lines:\n            if not isinstance(line, SoupString):\n                raise TypeError(\"HTML lines should be of type SoupString\")\n            soup = line.soup\n            header_elements = soup.find_all(\"th\")\n            if header_elements:\n                # Return multicolumns as tuples for HTMLHeader handling\n                yield [\n                    (el.text.strip(), el[\"colspan\"])\n                    if el.has_attr(\"colspan\")\n                    else el.text.strip()\n                    for el in header_elements\n                ]\n            data_elements = soup.find_all(\"td\")\n            if data_elements:\n                yield [el.text.strip() for el in data_elements]\n        if len(lines) == 0:\n            raise core.InconsistentTableError(\n                \"HTML tables must contain data in a <table> tag\"\n            )\n\n\nclass HTMLOutputter(core.TableOutputter):\n    \"\"\"\n    Output the HTML data as an ``astropy.table.Table`` object.\n\n    This subclass allows for the final table to contain\n    multidimensional columns (defined using the colspan attribute\n    of <th>).\n    \"\"\"\n\n    default_converters = [\n        core.convert_numpy(int),\n        core.convert_numpy(float),\n        core.convert_numpy(str),\n    ]\n\n    def __call__(self, cols, meta):\n        \"\"\"\n        Process the data in multidimensional columns.\n        \"\"\"\n        new_cols = []\n        col_num = 0\n\n        while col_num < len(cols):\n            col = cols[col_num]\n            if hasattr(col, \"colspan\"):\n                # Join elements of spanned columns together into list of tuples\n                span_cols = cols[col_num : col_num + col.colspan]\n                new_col = core.Column(col.name)\n                new_col.str_vals = list(zip(*[x.str_vals for x in span_cols]))\n                new_cols.append(new_col)\n                col_num += col.colspan\n            else:\n                new_cols.append(col)\n                col_num += 1\n\n        return super().__call__(new_cols, meta)\n\n\nclass HTMLHeader(core.BaseHeader):\n    splitter_class = HTMLSplitter\n\n    def start_line(self, lines):\n        \"\"\"\n        Return the line number at which header data begins.\n        \"\"\"\n        for i, line in enumerate(lines):\n            if not isinstance(line, SoupString):\n                raise TypeError(\"HTML lines should be of type SoupString\")\n            soup = line.soup\n            if soup.th is not None:\n                return i\n\n        return None\n\n    def _set_cols_from_names(self):\n        \"\"\"\n        Set columns from header names, handling multicolumns appropriately.\n        \"\"\"\n        self.cols = []\n        new_names = []\n\n        for name in self.names:\n            if isinstance(name, tuple):\n                col = core.Column(name=name[0])\n                col.colspan = int(name[1])\n                self.cols.append(col)\n                new_names.append(name[0])\n                for i in range(1, int(name[1])):\n                    # Add dummy columns\n                    self.cols.append(core.Column(\"\"))\n                    new_names.append(\"\")\n            else:\n                self.cols.append(core.Column(name=name))\n                new_names.append(name)\n\n        self.names = new_names\n\n\nclass HTMLData(core.BaseData):\n    splitter_class = HTMLSplitter\n\n    def start_line(self, lines):\n        \"\"\"\n        Return the line number at which table data begins.\n        \"\"\"\n        for i, line in enumerate(lines):\n            if not isinstance(line, SoupString):\n                raise TypeError(\"HTML lines should be of type SoupString\")\n            soup = line.soup\n\n            if soup.td is not None:\n                if soup.th is not None:\n                    raise core.InconsistentTableError(\n                        \"HTML tables cannot have headings and data in the same row\"\n                    )\n                return i\n\n        raise core.InconsistentTableError(\"No start line found for HTML data\")\n\n    def end_line(self, lines):\n        \"\"\"\n        Return the line number at which table data ends.\n        \"\"\"\n        last_index = -1\n\n        for i, line in enumerate(lines):\n            if not isinstance(line, SoupString):\n                raise TypeError(\"HTML lines should be of type SoupString\")\n            soup = line.soup\n            if soup.td is not None:\n                last_index = i\n\n        if last_index == -1:\n            return None\n        return last_index + 1\n\n\nclass HTML(core.BaseReader):\n    \"\"\"HTML format table.\n\n    In order to customize input and output, a dict of parameters may\n    be passed to this class holding specific customizations.\n\n    **htmldict** : Dictionary of parameters for HTML input/output.\n\n        * css : Customized styling\n            If present, this parameter will be included in a <style>\n            tag and will define stylistic attributes of the output.\n\n        * table_id : ID for the input table\n            If a string, this defines the HTML id of the table to be processed.\n            If an integer, this specifies the index of the input table in the\n            available tables. Unless this parameter is given, the reader will\n            use the first table found in the input file.\n\n        * multicol : Use multi-dimensional columns for output\n            The writer will output tuples as elements of multi-dimensional\n            columns if this parameter is true, and if not then it will\n            use the syntax 1.36583e-13 .. 1.36583e-13 for output. If not\n            present, this parameter will be true by default.\n\n        * raw_html_cols : column name or list of names with raw HTML content\n            This allows one to include raw HTML content in the column output,\n            for instance to include link references in a table.  This option\n            requires that the bleach package be installed.  Only whitelisted\n            tags are allowed through for security reasons (see the\n            raw_html_clean_kwargs arg).\n\n        * raw_html_clean_kwargs : dict of keyword args controlling HTML cleaning\n            Raw HTML will be cleaned to prevent unsafe HTML from ending up in\n            the table output.  This is done by calling ``bleach.clean(data,\n            **raw_html_clean_kwargs)``.  For details on the available options\n            (e.g. tag whitelist) see:\n            https://bleach.readthedocs.io/en/latest/clean.html\n\n        * parser : Specific HTML parsing library to use\n            If specified, this specifies which HTML parsing library\n            BeautifulSoup should use as a backend. The options to choose\n            from are 'html.parser' (the standard library parser), 'lxml'\n            (the recommended parser), 'xml' (lxml's XML parser), and\n            'html5lib'. html5lib is a highly lenient parser and therefore\n            might work correctly for unusual input if a different parser\n            fails.\n\n        * jsfiles : list of js files to include when writing table.\n\n        * cssfiles : list of css files to include when writing table.\n\n        * js : js script to include in the body when writing table.\n\n        * table_class : css class for the table\n\n    \"\"\"\n\n    _format_name = \"html\"\n    _io_registry_format_aliases = [\"html\"]\n    _io_registry_suffix = \".html\"\n    _description = \"HTML table\"\n\n    header_class = HTMLHeader\n    data_class = HTMLData\n    inputter_class = HTMLInputter\n\n    max_ndim = 2  # HTML supports writing 2-d columns with shape (n, m)\n\n    def __init__(self, htmldict=None):\n        if htmldict is None:\n            htmldict = {}\n        \"\"\"\n        Initialize classes for HTML reading and writing.\n        \"\"\"\n        super().__init__()\n        self.html = deepcopy(htmldict)\n        if \"multicol\" not in htmldict:\n            self.html[\"multicol\"] = True\n        if \"table_id\" not in htmldict:\n            self.html[\"table_id\"] = 1\n        self.inputter.html = self.html\n\n    def read(self, table):\n        \"\"\"\n        Read the ``table`` in HTML format and return a resulting ``Table``.\n        \"\"\"\n        self.outputter = HTMLOutputter()\n        return super().read(table)\n\n    def write(self, table):\n        \"\"\"\n        Return data in ``table`` converted to HTML as a list of strings.\n        \"\"\"\n        # Check that table has only 1-d or 2-d columns. Above that fails.\n        self._check_multidim_table(table)\n\n        cols = list(table.columns.values())\n\n        self.data.header.cols = cols\n        self.data.cols = cols\n\n        if isinstance(self.data.fill_values, tuple):\n            self.data.fill_values = [self.data.fill_values]\n\n        self.data._set_fill_values(cols)\n        self.data._set_col_formats()\n\n        lines = []\n\n        # Set HTML escaping to False for any column in the raw_html_cols input\n        raw_html_cols = self.html.get(\"raw_html_cols\", [])\n        if isinstance(raw_html_cols, str):\n            raw_html_cols = [raw_html_cols]  # Allow for a single string as input\n        cols_escaped = [col.info.name not in raw_html_cols for col in cols]\n\n        # Kwargs that get passed on to bleach.clean() if that is available.\n        raw_html_clean_kwargs = self.html.get(\"raw_html_clean_kwargs\", {})\n\n        # Use XMLWriter to output HTML to lines\n        w = writer.XMLWriter(ListWriter(lines))\n\n        with w.tag(\"html\"):\n            with w.tag(\"head\"):\n                # Declare encoding and set CSS style for table\n                with w.tag(\"meta\", attrib={\"charset\": \"utf-8\"}):\n                    pass\n                with w.tag(\n                    \"meta\",\n                    attrib={\n                        \"http-equiv\": \"Content-type\",\n                        \"content\": \"text/html;charset=UTF-8\",\n                    },\n                ):\n                    pass\n                if \"css\" in self.html:\n                    with w.tag(\"style\"):\n                        w.data(self.html[\"css\"])\n                if \"cssfiles\" in self.html:\n                    for filename in self.html[\"cssfiles\"]:\n                        with w.tag(\n                            \"link\", rel=\"stylesheet\", href=filename, type=\"text/css\"\n                        ):\n                            pass\n                if \"jsfiles\" in self.html:\n                    for filename in self.html[\"jsfiles\"]:\n                        with w.tag(\"script\", src=filename):\n                            # need this instead of pass to get <script></script>\n                            w.data(\"\")\n            with w.tag(\"body\"):\n                if \"js\" in self.html:\n                    with w.xml_cleaning_method(\"none\"):\n                        with w.tag(\"script\"):\n                            w.data(self.html[\"js\"])\n                if isinstance(self.html[\"table_id\"], str):\n                    html_table_id = self.html[\"table_id\"]\n                else:\n                    html_table_id = None\n                if \"table_class\" in self.html:\n                    html_table_class = self.html[\"table_class\"]\n                    attrib = {\"class\": html_table_class}\n                else:\n                    attrib = {}\n                with w.tag(\"table\", id=html_table_id, attrib=attrib):\n                    with w.tag(\"thead\"):\n                        with w.tag(\"tr\"):\n                            for col in cols:\n                                if len(col.shape) > 1 and self.html[\"multicol\"]:\n                                    # Set colspan attribute for multicolumns\n                                    w.start(\"th\", colspan=col.shape[1])\n                                else:\n                                    w.start(\"th\")\n                                w.data(col.info.name.strip())\n                                w.end(indent=False)\n                        col_str_iters = []\n                        new_cols_escaped = []\n\n                        # Make a container to hold any new_col objects created\n                        # below for multicolumn elements.  This is purely to\n                        # maintain a reference for these objects during\n                        # subsequent iteration to format column values.  This\n                        # requires that the weakref info._parent be maintained.\n                        new_cols = []\n\n                        for col, col_escaped in zip(cols, cols_escaped):\n                            if len(col.shape) > 1 and self.html[\"multicol\"]:\n                                span = col.shape[1]\n                                for i in range(span):\n                                    # Split up multicolumns into separate columns\n                                    new_col = Column([el[i] for el in col])\n\n                                    new_col_iter_str_vals = self.fill_values(\n                                        col, new_col.info.iter_str_vals()\n                                    )\n                                    col_str_iters.append(new_col_iter_str_vals)\n                                    new_cols_escaped.append(col_escaped)\n                                    new_cols.append(new_col)\n                            else:\n                                col_iter_str_vals = self.fill_values(\n                                    col, col.info.iter_str_vals()\n                                )\n                                col_str_iters.append(col_iter_str_vals)\n\n                                new_cols_escaped.append(col_escaped)\n\n                    for row in zip(*col_str_iters):\n                        with w.tag(\"tr\"):\n                            for el, col_escaped in zip(row, new_cols_escaped):\n                                # Potentially disable HTML escaping for column\n                                method = \"escape_xml\" if col_escaped else \"bleach_clean\"\n                                with w.xml_cleaning_method(\n                                    method, **raw_html_clean_kwargs\n                                ):\n                                    w.start(\"td\")\n                                    w.data(el.strip())\n                                    w.end(indent=False)\n\n        # Fixes XMLWriter's insertion of unwanted line breaks\n        return [\"\".join(lines)]\n\n    def fill_values(self, col, col_str_iters):\n        \"\"\"\n        Return an iterator of the values with replacements based on fill_values.\n        \"\"\"\n        # check if the col is a masked column and has fill values\n        is_masked_column = hasattr(col, \"mask\")\n        has_fill_values = hasattr(col, \"fill_values\")\n\n        for idx, col_str in enumerate(col_str_iters):\n            if is_masked_column and has_fill_values:\n                if col.mask[idx]:\n                    yield col.fill_values[core.masked]\n                    continue\n\n            if has_fill_values:\n                if col_str in col.fill_values:\n                    yield col.fill_values[col_str]\n                    continue\n\n            yield col_str\n"}}