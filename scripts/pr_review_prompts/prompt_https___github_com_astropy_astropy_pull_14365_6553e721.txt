Please review the following commit for potential bugs:

```
diff --git a/CHANGES.rst b/CHANGES.rst
index 83948c7d39f2..d262f04301d6 100644
--- a/CHANGES.rst
+++ b/CHANGES.rst
@@ -1,6 +1,251 @@
 4.2.1 (2021-4-1)
 ================
 
+New Features
+------------
+
+astropy.config
+^^^^^^^^^^^^^^
+
+astropy.constants
+^^^^^^^^^^^^^^^^^
+
+astropy.convolution
+^^^^^^^^^^^^^^^^^^^
+
+astropy.coordinates
+^^^^^^^^^^^^^^^^^^^
+
+- Adds the ability to create topocentric ``CIRS`` frames. Using these,
+  ``AltAz`` calculations are now accurate down to the milli-arcsecond
+  level. [#10994]
+
+- Adds a direct transformation from ``ICRS`` to ``AltAz`` frames. This
+  provides a modest speedup of approximately 10 percent. [#11079]
+
+- Adds new ``WGS84GeodeticRepresentation``, ``WGS72GeodeticRepresentation``,
+  and ``GRS80GeodeticRepresentation``. These are mostly for use inside
+  ``EarthLocation`` but can also be used to convert between geocentric
+  (cartesian) and different geodetic representations directly. [#11086]
+
+astropy.cosmology
+^^^^^^^^^^^^^^^^^
+
+astropy.extern
+^^^^^^^^^^^^^^
+
+astropy.io.ascii
+^^^^^^^^^^^^^^^^
+
+astropy.io.fits
+^^^^^^^^^^^^^^^
+
+- Check that the SIMPLE card is present when opening a file, to ensure that the
+  file is a valid FITS file and raise a better error when opening a non FITS
+  one. ``ignore_missing_simple`` can be used to skip this verification. [#10895]
+
+- Added ``append`` keyword to append table objects to an existing FITS file [#2632, #11149]
+
+- Expose ``Header.strip`` as a public method, to remove the most common
+  structural keywords. [#11174]
+
+astropy.io.misc
+^^^^^^^^^^^^^^^
+
+astropy.io.registry
+^^^^^^^^^^^^^^^^^^^
+
+- Readers and writers can now set a priority, to assist with resolving which
+  format to use. [#11214]
+
+astropy.io.votable
+^^^^^^^^^^^^^^^^^^
+
+- Version 1.4 VOTables now use the VOUnit format specification. [#11032]
+
+astropy.modeling
+^^^^^^^^^^^^^^^^
+
+- Added a state attribute to models to allow preventing the synching of
+  constraint values from the constituent models. This synching can
+  greatly slow down fitting if there are large numbers of fit parameters.
+  model.sync_constraints = True means check constituent model constraints
+  for compound models every time the constraint is accessed, False, do not.
+  Fitters that support constraints will set this to False on the model copy
+  and then set back to True when the fit is complete before returning.
+  [#11365].
+
+astropy.nddata
+^^^^^^^^^^^^^^
+
+astropy.samp
+^^^^^^^^^^^^
+
+astropy.stats
+^^^^^^^^^^^^^
+
+astropy.table
+^^^^^^^^^^^^^
+
+- Add table attributes to include or exclude columns from the output when
+  printing a table. This functionality includes a context manager to
+  include/exclude columns temporarily. [#11190]
+
+- Improved the string representation of objects related to ``Table.indices`` so
+  they now indicate the object type and relevant attributes. [#11333]
+
+astropy.tests
+^^^^^^^^^^^^^
+
+astropy.time
+^^^^^^^^^^^^
+
+astropy.timeseries
+^^^^^^^^^^^^^^^^^^
+
+astropy.uncertainty
+^^^^^^^^^^^^^^^^^^^
+
+astropy.units
+^^^^^^^^^^^^^
+
+astropy.utils
+^^^^^^^^^^^^^
+
+- ``astropy.utils.data.get_pkg_data_path`` is publicly scoped (previously the private
+  function ``_find_pkg_data_path``) for obtaining file paths without checking if the
+  file/directory exists, as long as the package and module do. [#11006]
+
+- Add new ``utils.parsing`` module to with helper wrappers around ``ply``. [#11227]
+
+- Deprecated ``astropy.utils.OrderedDescriptor`` and
+  ``astropy.utils.OrderedDescriptorContainer``, as new features in Python 3
+  make their use less compelling. [#11094, #11099]
+
+astropy.visualization
+^^^^^^^^^^^^^^^^^^^^^
+
+astropy.wcs
+^^^^^^^^^^^
+- Add IVOA UCD mappings for some FITS WCS keywords commonly used in solar physics. [#10965]
+
+- Add ``STOKES`` FITS WCS keyword to the IVOA UCD mapping. [#11236]
+
+API Changes
+-----------
+
+astropy.config
+^^^^^^^^^^^^^^
+
+astropy.constants
+^^^^^^^^^^^^^^^^^
+
+astropy.convolution
+^^^^^^^^^^^^^^^^^^^
+
+astropy.coordinates
+^^^^^^^^^^^^^^^^^^^
+
+- For input to representations, subclasses of the class required for a
+  given attribute will now be allowed in. [#11113]
+
+astropy.cosmology
+^^^^^^^^^^^^^^^^^
+
+- Clarified definition of inputs to ``angular_diameter_distance_z1z2``.
+  The function now emits ``AstropyUserWarning`` when ``z2`` is less than ``z1``.
+  [#11197]
+
+astropy.extern
+^^^^^^^^^^^^^^
+
+astropy.io.ascii
+^^^^^^^^^^^^^^^^
+
+- Added support for reading and writing ASCII tables in QDP (Quick and Dandy Plotter) format. [#11256]
+
+astropy.io.fits
+^^^^^^^^^^^^^^^
+
+- For conversion between FITS tables and astropy ``Table``, the standard mask
+  values of ``NaN`` for float and null string for string are now properly
+  recognized, leading to a ``MaskedColumn`` with appropriately set mask
+  instead of a ``Column`` with those values exposed. Conversely, when writing
+  an astropy ``Table`` to a FITS tables, masked values are now consistently
+  converted to the standard FITS mask values of ``NaN`` for float and null
+  string for string (i.e., not just for tables with ``masked=True``, which no
+  longer is guaranteed to signal the presence of ``MaskedColumn``). [#11222]
+
+astropy.io.misc
+^^^^^^^^^^^^^^^
+
+astropy.io.votable
+^^^^^^^^^^^^^^^^^^
+
+astropy.modeling
+^^^^^^^^^^^^^^^^
+
+- Removed deprecated ``astropy.modeling.blackbody`` module. [#10972]
+
+astropy.nddata
+^^^^^^^^^^^^^^
+
+astropy.samp
+^^^^^^^^^^^^
+
+astropy.stats
+^^^^^^^^^^^^^
+
+astropy.table
+^^^^^^^^^^^^^
+
+- Added ``Column.value`` as an alias for the existing ``Column.data`` attribute.
+  This makes accessing a column's underlying data array consistent with the
+  ``.value`` attribute available for ``Time`` and ``Quantity`` objects. [#10962]
+
+- In reading from a FITS tables, the standard mask values of ``NaN`` for float
+  and null string for string are properly recognized, leading to a
+  ``MaskedColumn`` with appropriately set mask. [#11222]
+
+- Changed the implementation of the ``table.index.Index`` class so instantiating
+  from this class now returns an ``Index`` object as expected instead of a
+  ``SlicedIndex`` object. [#11333]
+
+astropy.tests
+^^^^^^^^^^^^^
+
+astropy.time
+^^^^^^^^^^^^
+
+astropy.timeseries
+^^^^^^^^^^^^^^^^^^
+
+astropy.uncertainty
+^^^^^^^^^^^^^^^^^^^
+
+astropy.units
+^^^^^^^^^^^^^
+
+- Calling ``Unit()`` with no argument now returns a dimensionless unit,
+  as was documented but not implemented. [#11295]
+
+astropy.utils
+^^^^^^^^^^^^^
+
+- Removed deprecated ``utils.misc.InheritDocstrings`` and ``utils.timer``. [#10281]
+
+- Removed usage of deprecated ``ipython`` stream in ``utils.console``. [#10942]
+
+astropy.visualization
+^^^^^^^^^^^^^^^^^^^^^
+
+astropy.wcs
+^^^^^^^^^^^
+
+- Deprecate ``accuracy`` argument in ``all_world2pix`` which was mistakenly
+  *documented*, in the case ``accuracy`` was ever used. [#11055]
+
+
 Bug Fixes
 ---------
 
diff --git a/astropy/io/ascii/__init__.py b/astropy/io/ascii/__init__.py
index e10998ac1222..9e1b79a196e0 100644
--- a/astropy/io/ascii/__init__.py
+++ b/astropy/io/ascii/__init__.py
@@ -35,6 +35,7 @@
 from .html import HTML
 from .ipac import Ipac
 from .daophot import Daophot
+from .qdp import QDP
 from .sextractor import SExtractor
 from .fixedwidth import (FixedWidth, FixedWidthNoHeader,
                          FixedWidthTwoLine, FixedWidthSplitter,
diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py
new file mode 100644
index 000000000000..b80c94637d82
--- /dev/null
+++ b/astropy/io/ascii/qdp.py
@@ -0,0 +1,559 @@
+# Licensed under a 3-clause BSD style license - see LICENSE.rst
+"""
+This package contains functions for reading and writing QDP tables that are
+not meant to be used directly, but instead are available as readers/writers in
+`astropy.table`. See :ref:`table_io` for more details.
+"""
+import re
+import copy
+import numpy as np
+import warnings
+from astropy.utils.exceptions import AstropyUserWarning
+from astropy.table import Table
+
+from . import core, basic
+
+
+def is_qdp(origin, filepath, fileobj, *args, **kwargs):
+    if filepath is not None:
+        return filepath.endswith(('.qdp'))
+    return False
+
+
+_decimal_re = r'[+-]?(\d+(\.\d*)?|\.\d+)([eE][+-]?\d+)?'
+_command_re = r'READ [TS]ERR(\s+[0-9]+)+'
+_new_re = r'NO(\s+NO)+'
+_data_re = rf'({_decimal_re}|NO|[-+]?nan)(\s+({_decimal_re}|NO|[-+]?nan))*)'
+_line_type_re = re.compile(rf'^\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\s*(\!(?P<comment>.*))?\s*$')
+
+
+def _line_type(line):
+    """Interpret a QDP file line
+
+    Parameters
+    ----------
+    line : str
+        a single line of the file
+
+    Returns
+    -------
+    type : str
+        Line type: "comment", "command", or "data"
+
+    Examples
+    --------
+    >>> _line_type("READ SERR 3")
+    'command'
+    >>> _line_type(" \\n    !some gibberish")
+    'comment'
+    >>> _line_type("   ")
+    'comment'
+    >>> _line_type(" 21345.45")
+    'data,1'
+    >>> _line_type(" 21345.45 1.53e-3 1e-3 .04 NO nan")
+    'data,6'
+    >>> _line_type(" 21345.45 ! a comment to disturb")
+    'data,1'
+    >>> _line_type("NO NO NO NO NO")
+    'new'
+    >>> _line_type("N O N NOON OON O")
+    Traceback (most recent call last):
+        ...
+    ValueError: Unrecognized QDP line...
+    >>> _line_type(" some non-comment gibberish")
+    Traceback (most recent call last):
+        ...
+    ValueError: Unrecognized QDP line...
+    """
+    line = line.strip()
+    if not line:
+        return 'comment'
+    match = _line_type_re.match(line)
+    if match is None:
+        raise ValueError(f'Unrecognized QDP line: {line}')
+    for type_, val in match.groupdict().items():
+        if val is None:
+            continue
+
+        if type_ == 'data':
+            return f'data,{len(val.split())}'
+        else:
+            return type_
+
+
+def _get_type_from_list_of_lines(lines):
+    """Read through the list of QDP file lines and label each line by type
+
+    Parameters
+    ----------
+    lines : list
+        List containing one file line in each entry
+
+    Returns
+    -------
+    contents : list
+        List containing the type for each line (see `line_type_and_data`)
+    ncol : int
+        The number of columns in the data lines. Must be the same throughout
+        the file
+
+    Examples
+    --------
+    >>> line0 = "! A comment"
+    >>> line1 = "543 12 456.0"
+    >>> lines = [line0, line1]
+    >>> types, ncol = _get_type_from_list_of_lines(lines)
+    >>> types[0]
+    'comment'
+    >>> types[1]
+    'data,3'
+    >>> ncol
+    3
+    >>> lines.append("23")
+    >>> _get_type_from_list_of_lines(lines)
+    Traceback (most recent call last):
+        ...
+    ValueError: Inconsistent number of columns
+    """
+
+    types = [_line_type(line) for line in lines]
+    current_ncol = None
+    for type_ in types:
+        if type_.startswith('data', ):
+            ncol = int(type_[5:])
+            if current_ncol is None:
+                current_ncol = ncol
+            elif ncol != current_ncol:
+                raise ValueError('Inconsistent number of columns')
+
+    return types, current_ncol
+
+
+def _get_lines_from_file(qdp_file):
+    if "\n" in qdp_file:
+        lines = qdp_file.split("\n")
+    else:
+        with open(qdp_file) as fobj:
+            lines = fobj.readlines()
+    return lines
+
+
+def _analyze_qdp_file(qdp_file):
+    """Read through the QDP file and label each line by type
+
+    Parameters
+    ----------
+    qdp_file : str
+        File name
+
+    Returns
+    -------
+    contents : list
+        List containing the type for each line (see `line_type_and_data`)
+    ncol : int
+        The number of columns in the data lines. Must be the same throughout
+        the file
+    """
+    lines = _get_lines_from_file(qdp_file)
+    return _get_type_from_list_of_lines(lines)
+
+
+def _interpret_err_lines(err_specs, ncols, names=None):
+    """Give list of column names from the READ SERR and TERR commands
+
+    Parameters
+    ----------
+    err_specs : dict, {'serr': [n0, n1, ...], 'terr': [n2, n3, ...]}
+        Error specifications for symmetric and two-sided errors
+    ncols : int
+        Number of data columns
+
+    Other parameters
+    ----------------
+    names : list of strings
+        Name of data columns (defaults to ['col1', 'col2', ...]), _not_
+        including error columns.
+
+    Returns
+    -------
+    colnames : list
+        List containing the column names. Error columns will have the name
+        of the main column plus ``_err`` for symmetric errors, and ``_perr``
+        and ``_nerr`` for positive and negative errors respectively
+
+    Examples
+    --------
+    >>> col_in = ['MJD', 'Rate']
+    >>> cols = _interpret_err_lines(None, 2, names=col_in)
+    >>> cols[0]
+    'MJD'
+    >>> err_specs = {'terr': [1], 'serr': [2]}
+    >>> ncols = 5
+    >>> cols = _interpret_err_lines(err_specs, ncols, names=col_in)
+    >>> cols[0]
+    'MJD'
+    >>> cols[2]
+    'MJD_nerr'
+    >>> cols[4]
+    'Rate_err'
+    >>> _interpret_err_lines(err_specs, 6, names=col_in)
+    Traceback (most recent call last):
+        ...
+    ValueError: Inconsistent number of input colnames
+    """
+
+    colnames = ["" for i in range(ncols)]
+    if err_specs is None:
+        serr_cols = terr_cols = []
+
+    else:
+        # I don't want to empty the original one when using `pop` below
+        err_specs = copy.deepcopy(err_specs)
+
+        serr_cols = err_specs.pop("serr", [])
+        terr_cols = err_specs.pop("terr", [])
+
+    if names is not None:
+        all_error_cols = len(serr_cols) + len(terr_cols) * 2
+        if all_error_cols + len(names) != ncols:
+            raise ValueError("Inconsistent number of input colnames")
+
+    shift = 0
+    for i in range(ncols):
+        col_num = i + 1 - shift
+        if colnames[i] != "":
+            continue
+
+        colname_root = f"col{col_num}"
+
+        if names is not None:
+            colname_root = names[col_num - 1]
+
+        colnames[i] = f"{colname_root}"
+        if col_num in serr_cols:
+            colnames[i + 1] = f"{colname_root}_err"
+            shift += 1
+            continue
+
+        if col_num in terr_cols:
+            colnames[i + 1] = f"{colname_root}_perr"
+            colnames[i + 2] = f"{colname_root}_nerr"
+            shift += 2
+            continue
+
+    assert not np.any([c == "" for c in colnames])
+
+    return colnames
+
+
+def _get_tables_from_qdp_file(qdp_file, input_colnames=None):
+    """Get all tables from a QDP file
+
+    Parameters
+    ----------
+    qdp_file : str
+        Input QDP file name
+
+    Other parameters
+    ----------------
+    names : list of strings
+        Name of data columns (defaults to ['col1', 'col2', ...]), _not_
+        including error columns.
+
+    Returns
+    -------
+    tables : list of `Table` objects
+        List containing all the tables present inside the QDP file
+    """
+
+    contents, ncol = _analyze_qdp_file(qdp_file)
+
+    lines = _get_lines_from_file(qdp_file)
+
+    table_list = []
+    err_specs = {}
+    colnames = None
+
+    comment_text = ""
+    initial_comments = ""
+    command_lines = ""
+    current_rows = None
+
+    for line, datatype in zip(lines, contents):
+        line = line.strip().lstrip('!')
+        # Is this a comment?
+        if datatype == "comment":
+            comment_text += line + '\n'
+            continue
+
+        if datatype == "command":
+            # The first time I find commands, I save whatever comments into
+            # The initial comments.
+            if command_lines == "":
+                initial_comments = comment_text
+                comment_text = ""
+
+            if err_specs != {}:
+                warnings.warn(
+                    "This file contains multiple command blocks. Please verify",
+                    AstropyUserWarning
+                )
+            command_lines += line + '\n'
+            continue
+
+        if datatype.startswith("data"):
+            # The first time I find data, I define err_specs
+            if err_specs == {} and command_lines != "":
+                for cline in command_lines.strip().split('\n'):
+                    command = cline.strip().split()
+                    if len(command) < 3:
+                        continue
+                    err_specs[command[1].lower()] = [int(c) for c in
+                                                     command[2:]]
+            if colnames is None:
+                colnames = _interpret_err_lines(
+                    err_specs, ncol, names=input_colnames
+                )
+
+            if current_rows is None:
+                current_rows = []
+
+            values = []
+            for v in line.split():
+                if v == "NO":
+                    values.append(np.ma.masked)
+                else:
+                    values.append(float(v))
+            current_rows.append(values)
+            continue
+
+        if datatype == "new":
+            # Save table to table_list and reset
+            if current_rows is not None:
+                new_table = Table(names=colnames, rows=current_rows)
+                new_table.meta["initial_comments"] = initial_comments.strip().split("\n")
+                new_table.meta["comments"] = comment_text.strip().split("\n")
+                # Reset comments
+                comment_text = ""
+                table_list.append(new_table)
+                current_rows = None
+            continue
+
+    # At the very end, if there is still a table being written, let's save
+    # it to the table_list
+    if current_rows is not None:
+        new_table = Table(names=colnames, rows=current_rows)
+        new_table.meta["initial_comments"] = initial_comments.strip().split("\n")
+        new_table.meta["comments"] = comment_text.strip().split("\n")
+        table_list.append(new_table)
+
+    return table_list
+
+
+def _understand_err_col(colnames):
+    """Get which column names are error columns
+
+    Examples
+    --------
+    >>> colnames = ['a', 'a_err', 'b', 'b_perr', 'b_nerr']
+    >>> serr, terr = _understand_err_col(colnames)
+    >>> np.allclose(serr, [1])
+    True
+    >>> np.allclose(terr, [2])
+    True
+    >>> serr, terr = _understand_err_col(['a', 'a_nerr'])
+    Traceback (most recent call last):
+    ...
+    ValueError: Missing positive error...
+    >>> serr, terr = _understand_err_col(['a', 'a_perr'])
+    Traceback (most recent call last):
+    ...
+    ValueError: Missing negative error...
+    """
+    shift = 0
+    serr = []
+    terr = []
+
+    for i, col in enumerate(colnames):
+        if col.endswith("_err"):
+            # The previous column, but they're numbered from 1!
+            # Plus, take shift into account
+            serr.append(i - shift)
+            shift += 1
+        elif col.endswith("_perr"):
+            terr.append(i - shift)
+            if len(colnames) == i + 1 or not colnames[i + 1].endswith('_nerr'):
+                raise ValueError("Missing negative error")
+            shift += 2
+        elif col.endswith("_nerr") and not colnames[i - 1].endswith('_perr'):
+            raise ValueError("Missing positive error")
+    return serr, terr
+
+
+def _read_table_qdp(qdp_file, names=None, table_id=None):
+    """Read a table from a QDP file
+
+    Parameters
+    ----------
+    qdp_file : str
+        Input QDP file name
+
+    Other parameters
+    ----------------
+    table_id : int, default 0
+        Number of the table to be read from the QDP file. This is useful
+        when multiple tables present in the file. By default, the first is read.
+
+    names : list of strings
+        Name of data columns (defaults to ['col1', 'col2', ...]), _not_
+        including error columns.
+
+    Returns
+    -------
+    tables : list of `Table` objects
+        List containing all the tables present inside the QDP file
+    """
+    if table_id is None:
+        warnings.warn("table_id not specified. Reading the first available "
+                      "table", AstropyUserWarning)
+        table_id = 0
+
+    tables = _get_tables_from_qdp_file(qdp_file, input_colnames=names)
+
+    return tables[table_id]
+
+
+def _write_table_qdp(table, filename=None, err_specs=None):
+    """Write a table to a QDP file
+
+    Parameters
+    ----------
+    table : :class:`~astropy.table.Table` object
+        Input table to be written
+    filename : str
+        Output QDP file name
+
+    Other parameters
+    ----------------
+    err_specs : dict
+        Dictionary of the format {'serr': [1], 'terr': [2, 3]}, specifying
+        which columns have symmetric and two-sided errors (see QDP format
+        specification)
+    """
+    import io
+    fobj = io.StringIO()
+
+    if 'initial_comments' in table.meta and table.meta['initial_comments'] != []:
+        for line in table.meta['initial_comments']:
+            line = line.strip()
+            if not line.startswith("!"):
+                line = "!" + line
+            print(line, file=fobj)
+
+    if err_specs is None:
+        serr_cols, terr_cols = _understand_err_col(table.colnames)
+    else:
+        serr_cols = err_specs.pop("serr", [])
+        terr_cols = err_specs.pop("terr", [])
+    if serr_cols != []:
+        col_string = " ".join([str(val) for val in serr_cols])
+        print(f"READ SERR {col_string}", file=fobj)
+    if terr_cols != []:
+        col_string = " ".join([str(val) for val in terr_cols])
+        print(f"READ TERR {col_string}", file=fobj)
+
+    if 'comments' in table.meta and table.meta['comments'] != []:
+        for line in table.meta['comments']:
+            line = line.strip()
+            if not line.startswith("!"):
+                line = "!" + line
+            print(line, file=fobj)
+
+    colnames = table.colnames
+    print("!" + " ".join(colnames), file=fobj)
+    for row in table:
+        values = []
+        for val in row:
+            if not np.ma.is_masked(val):
+                rep = str(val)
+            else:
+                rep = "NO"
+            values.append(rep)
+        print(" ".join(values), file=fobj)
+
+    full_string = fobj.getvalue()
+    fobj.close()
+
+    if filename is not None:
+        with open(filename, 'w') as fobj:
+            print(full_string, file=fobj)
+
+    return full_string.split("\n")
+
+
+class QDPSplitter(core.DefaultSplitter):
+    """
+    Split on space for QDP tables
+    """
+    delimiter = ' '
+
+
+class QDPHeader(basic.CommentedHeaderHeader):
+    """
+    Header that uses the :class:`astropy.io.ascii.basic.QDPSplitter`
+    """
+    splitter_class = QDPSplitter
+    comment = "!"
+    write_comment = "!"
+
+
+class QDPData(basic.BasicData):
+    """
+    Data that uses the :class:`astropy.io.ascii.basic.CsvSplitter`
+    """
+    splitter_class = QDPSplitter
+    fill_values = [(core.masked, 'NO')]
+    comment = "!"
+    write_comment = None
+
+
+class QDP(basic.Basic):
+    """QDP table.
+
+    This file format can contain multiple tables, separated by a line full
+    of ``NO``s. Comments are exclamation marks, and missing values are single
+    ``NO`` entries.
+    Headers are just comments, and tables distributed by various missions
+    can differ greatly in their use of conventions. For example, light curves
+    distributed by the Swift-Gehrels mission have an extra space in one header
+    entry that makes the number of labels inconsistent with the number of cols
+
+    ::
+                      Extra space
+                          |
+                          v
+       !     MJD       Err (pos)       Err(neg)        Rate            Error
+        53000.123456   2.378e-05     -2.378472e-05     NO             0.212439
+
+    """
+    _format_name = 'qdp'
+    _io_registry_can_write = True
+    _io_registry_suffix = '.qdp'
+    _description = 'Quick and Dandy Plotter'
+
+    header_class = QDPHeader
+    data_class = QDPData
+
+    def __init__(self, table_id=None, names=None, err_specs=None):
+        super().__init__()
+        self.table_id = table_id
+        self.names = names
+        self.err_specs = err_specs
+
+    def read(self, qdp_file):
+        return _read_table_qdp(qdp_file, table_id=self.table_id,
+                               names=self.names)
+
+    def write(self, table):
+        lines = _write_table_qdp(table, err_specs=self.err_specs)
+        return lines
diff --git a/astropy/io/ascii/tests/test_qdp.py b/astropy/io/ascii/tests/test_qdp.py
new file mode 100644
index 000000000000..51803a76c3cf
--- /dev/null
+++ b/astropy/io/ascii/tests/test_qdp.py
@@ -0,0 +1,190 @@
+import numpy as np
+import pytest
+from astropy.io import ascii
+from astropy.io.ascii.qdp import _read_table_qdp, _write_table_qdp
+from astropy.table import Table, Column, MaskedColumn
+from astropy.utils.exceptions import AstropyUserWarning
+
+
+def test_get_tables_from_qdp_file(tmpdir):
+    example_qdp = """
+    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2
+    ! Columns are as labelled
+    READ TERR 1
+    READ SERR 2
+    ! WT -- hard data
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.212439       0.212439
+    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000
+    NO NO NO NO NO
+    ! WT -- soft data
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890
+    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592
+    NO NO NO NO NO
+    ! WT -- hardness ratio
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935
+    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        -nan
+    """
+
+    path = str(tmpdir.join('test.qdp'))
+
+    with open(path, "w") as fp:
+        print(example_qdp, file=fp)
+
+    table0 = _read_table_qdp(fp.name, names=["MJD", "Rate"], table_id=0)
+    assert table0.meta["initial_comments"][0].startswith("Swift")
+    assert table0.meta["comments"][0].startswith("WT -- hard data")
+    table2 = _read_table_qdp(fp.name, names=["MJD", "Rate"], table_id=2)
+    assert table2.meta["initial_comments"][0].startswith("Swift")
+    assert table2.meta["comments"][0].startswith("WT -- hardness")
+    assert np.isclose(table2["MJD_nerr"][0], -2.37847222222222e-05)
+
+
+def test_roundtrip(tmpdir):
+    example_qdp = """
+    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2
+    ! Columns are as labelled
+    READ TERR 1
+    READ SERR 2
+    ! WT -- hard data
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   NO       0.212439
+    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000
+    NO NO NO NO NO
+    ! WT -- soft data
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890
+    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592
+    NO NO NO NO NO
+    ! WT -- hardness ratio
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935
+    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        NO
+    ! Add command, just to raise the warning.
+    READ TERR 1
+    ! WT -- whatever
+    !MJD            Err (pos)       Err(neg)        Rate            Error
+    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935
+    NO 1.14467592592593e-05    -1.14467592592593e-05   0.000000        NO
+    """
+
+    path = str(tmpdir.join('test.qdp'))
+    path2 = str(tmpdir.join('test2.qdp'))
+
+    with open(path, "w") as fp:
+        print(example_qdp, file=fp)
+    with pytest.warns(AstropyUserWarning) as record:
+        table = _read_table_qdp(path, names=["MJD", "Rate"],
+                                table_id=0)
+    assert np.any(["This file contains multiple command blocks"
+                   in r.message.args[0]
+                   for r in record])
+
+    _write_table_qdp(table, path2)
+
+    new_table = _read_table_qdp(path2, names=["MJD", "Rate"], table_id=0)
+
+    for col in new_table.colnames:
+        is_masked = np.array([np.ma.is_masked(val) for val in new_table[col]])
+        if np.any(is_masked):
+            # All NaN values are read as such.
+            assert np.ma.is_masked(table[col][is_masked])
+
+        is_nan = np.array([(not np.ma.is_masked(val) and np.isnan(val))
+                           for val in new_table[col]])
+        # All non-NaN values are the same
+        assert np.allclose(new_table[col][~is_nan], table[col][~is_nan])
+        if np.any(is_nan):
+            # All NaN values are read as such.
+            assert np.isnan(table[col][is_nan])
+    assert np.allclose(new_table['MJD_perr'], [2.378472e-05, 1.1446759e-05])
+
+    for meta_name in ['initial_comments', 'comments']:
+        assert meta_name in new_table.meta
+
+
+def test_read_example(tmpdir):
+    example_qdp = """
+        ! Initial comment line 1
+        ! Initial comment line 2
+        READ TERR 1
+        READ SERR 3
+        ! Table 0 comment
+        !MJD            Err (pos)       Err(neg)        Rate            Error   Value
+        53000.5   0.25  -0.5   1  1.5  3.5 2
+        54000.5   1.25  -1.5   2  2.5  4.5 3
+        NO NO NO NO NO
+        ! Table 1 comment
+        !MJD            Err (pos)       Err(neg)        Rate            Error   Value
+        54000.5   2.25  -2.5   NO  3.5  5.5 5
+        55000.5   3.25  -3.5   4  4.5  6.5 nan
+        """
+    dat = ascii.read(example_qdp, format='qdp', table_id=1,
+                     names=['a', 'b', 'c', 'd'])
+    t = Table.read(example_qdp, format='ascii.qdp', table_id=1,
+                   names=['a', 'b', 'c', 'd'])
+
+    assert np.allclose(t['a'], [54000, 55000])
+    assert t['c_err'][0] == 5.5
+    assert np.ma.is_masked(t['b'][0])
+    assert np.isnan(t['d'][1])
+
+    t.values_equal(dat)
+
+
+def test_roundtrip_example(tmpdir):
+    example_qdp = """
+        ! Initial comment line 1
+        ! Initial comment line 2
+        READ TERR 1
+        READ SERR 3
+        ! Table 0 comment
+        !MJD            Err (pos)       Err(neg)        Rate            Error   Value
+        53000.5   0.25  -0.5   1  1.5  3.5 2
+        54000.5   1.25  -1.5   2  2.5  4.5 3
+        NO NO NO NO NO
+        ! Table 1 comment
+        !MJD            Err (pos)       Err(neg)        Rate            Error   Value
+        54000.5   2.25  -2.5   NO  3.5  5.5 5
+        55000.5   3.25  -3.5   4  4.5  6.5 nan
+        """
+    test_file = str(tmpdir.join('test.qdp'))
+
+    t = Table.read(example_qdp, format='ascii.qdp', table_id=1,
+                   names=['a', 'b', 'c', 'd'])
+    t.write(test_file, err_specs={'terr': [1], 'serr': [3]})
+    t2 = Table.read(test_file, names=['a', 'b', 'c', 'd'], table_id=0)
+
+    t.values_equal(t2)
+
+
+def test_read_write_simple(tmpdir):
+    test_file = str(tmpdir.join('test.qdp'))
+    t1 = Table()
+    t1.add_column(Column(name='a', data=[1, 2, 3, 4]))
+    t1.add_column(MaskedColumn(data=[4., np.nan, 3., 1.], name='b',
+                               mask=[False, False, False, True]))
+    t1.write(test_file, format='ascii.qdp')
+    with pytest.warns(UserWarning) as record:
+        t2 = Table.read(test_file, format='ascii.qdp')
+    assert np.any(["table_id not specified. Reading the first available table"
+                   in r.message.args[0]
+                   for r in record])
+
+    assert np.allclose(t2['col1'], t1['a'])
+    assert np.all(t2['col1'] == t1['a'])
+
+    good = ~np.isnan(t1['b'])
+    assert np.allclose(t2['col2'][good], t1['b'][good])
+
+
+def test_read_write_simple_specify_name(tmpdir):
+    test_file = str(tmpdir.join('test.qdp'))
+    t1 = Table()
+    t1.add_column(Column(name='a', data=[1, 2, 3]))
+    # Give a non-None err_specs
+    t1.write(test_file, format='ascii.qdp')
+    t2 = Table.read(test_file, table_id=0, format='ascii.qdp', names=['a'])
+    assert np.all(t2['a'] == t1['a'])
diff --git a/docs/io/ascii/index.rst b/docs/io/ascii/index.rst
index 76ee27194c13..df42c2974651 100644
--- a/docs/io/ascii/index.rst
+++ b/docs/io/ascii/index.rst
@@ -256,6 +256,7 @@ are compatible with the fast Cython/C engine for reading and writing.
 ``ipac``                    Yes      :class:`~astropy.io.ascii.Ipac`: IPAC format table
 ``latex``                   Yes      :class:`~astropy.io.ascii.Latex`: LaTeX table
 ``no_header``               Yes  Yes :class:`~astropy.io.ascii.NoHeader`: Basic table with no headers
+``qdp``                     Yes      :class:`~astropy.io.ascii.QDP`: Quick and Dandy Plotter files
 ``rdb``                     Yes  Yes :class:`~astropy.io.ascii.Rdb`: Tab-separated with a type definition header line
 ``rst``                     Yes      :class:`~astropy.io.ascii.RST`: reStructuredText simple format table
 ``sextractor``                       :class:`~astropy.io.ascii.SExtractor`: SExtractor format table
diff --git a/docs/io/unified.rst b/docs/io/unified.rst
index 6759db8bf412..8b377570f32b 100644
--- a/docs/io/unified.rst
+++ b/docs/io/unified.rst
@@ -202,6 +202,7 @@ ascii.fixed_width_no_header    Yes          :class:`~astropy.io.ascii.FixedWidth
                  ascii.ipac    Yes          :class:`~astropy.io.ascii.Ipac`: IPAC format table
                 ascii.latex    Yes    .tex  :class:`~astropy.io.ascii.Latex`: LaTeX table
             ascii.no_header    Yes          :class:`~astropy.io.ascii.NoHeader`: Basic table with no headers
+                  ascii.qdp    Yes    .qdp   :class:`~astropy.io.ascii.QDP`: Quick and Dandy Plotter files
                   ascii.rdb    Yes    .rdb  :class:`~astropy.io.ascii.Rdb`: Tab-separated with a type definition header line
                   ascii.rst    Yes    .rst  :class:`~astropy.io.ascii.RST`: reStructuredText simple format table
            ascii.sextractor     No          :class:`~astropy.io.ascii.SExtractor`: SExtractor format table

```

Focus on identifying issues that represent objectively incorrect behavior, could lead to exceptions or program crashes, or constitute security vulnerabilities.

Report all of your findings in a single JSON object with the following format:

{
  "issues": [
    {
      "file": "src/App.tsx",
      "line": 42,
      "description": "Memory leak in useEffect cleanup"
    }
  ]
}